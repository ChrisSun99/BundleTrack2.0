{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOKWlc8H6X+OTpjdbQWLwCn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"KS2COkRboBO8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688678106593,"user_tz":240,"elapsed":1952,"user":{"displayName":"Bowen Jiang","userId":"17762967857481884350"}},"outputId":"6b55e6b7-402b-4baa-abf1-128eeeeb1d5d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n","Thu Jul  6 21:15:06 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive/\", force_remount=True)\n","import os\n","\n","os.chdir(\"/content/gdrive/MyDrive/bundletrack_process_depth\")\n","!nvidia-smi"]},{"cell_type":"code","source":["# !pip install moviepy\n","# !pip install timm"],"metadata":{"id":"qIaa31_V-bcg","executionInfo":{"status":"ok","timestamp":1688678106593,"user_tz":240,"elapsed":3,"user":{"displayName":"Bowen Jiang","userId":"17762967857481884350"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# convert video to frames\n","video_path = \"4016_toss1.mov\"\n","frames_folder = \"frames/\"\n","\n","from moviepy.editor import VideoFileClip\n","import cv2\n","from tqdm import tqdm\n","\n","# Create the destination folder if it doesn't exist\n","if not os.path.exists(frames_folder):\n","    os.makedirs(frames_folder)\n","\n","# Load the video clip\n","clip = VideoFileClip(video_path)\n","\n","# Iterate through each frame in the video\n","for i, frame in tqdm(enumerate(clip.iter_frames())):\n","    # Construct the frame filename\n","    frame_filename = os.path.join(frames_folder, f\"frame_{i}.png\")\n","\n","    # Convert the frame to RGB format (if necessary)\n","    if frame.ndim == 3:\n","        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","    # Save the frame as a JPEG image\n","    cv2.imwrite(frame_filename, frame)\n"],"metadata":{"id":"s-qjLKdZ7s_w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688683252491,"user_tz":240,"elapsed":296368,"user":{"displayName":"Bowen Jiang","userId":"17762967857481884350"}},"outputId":"34b4b011-c6bb-4952-8209-359a768fae34"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stderr","text":["1618it [04:55,  5.52it/s]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file 4016_toss1.mov, 6220800 bytes wanted but 0 bytes read,at frame 1618/1619, at time 53.93/53.95 sec. Using the last valid frame instead.\n","  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n","\n","1619it [04:56,  5.47it/s]\n"]}]},{"cell_type":"code","source":["import torch\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import torchvision.transforms as transforms\n","import numpy as np\n","import torch.nn.functional as F"],"metadata":{"id":"4OhTriESIqg3","executionInfo":{"status":"ok","timestamp":1688683257114,"user_tz":240,"elapsed":149,"user":{"displayName":"Bowen Jiang","userId":"17762967857481884350"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# load pretrained depth estimator network\n","model_type = 'DPT_Large'\n","depth_estimator = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n","depth_estimator.to(device)\n","depth_estimator.eval();"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XZAN5xCCBmkw","executionInfo":{"status":"ok","timestamp":1688681289602,"user_tz":240,"elapsed":9537,"user":{"displayName":"Bowen Jiang","userId":"17762967857481884350"}},"outputId":"4fd60369-4865-4429-e31b-441b6eca07e4"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"]}]},{"cell_type":"code","source":["fig = plt.figure(figsize=(6, 4))\n","\n","image_transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.CenterCrop(size=(1080, 1440)),\n","     transforms.Resize(size=(480, 640))]\n",")\n","\n","# load all images in dataset\n","source_folder = \"frames/\"\n","destination_folder = \"depths/\"\n","\n","image_paths = []\n","for filename in os.listdir(source_folder):\n","    image_paths.append(filename)\n","\n","with torch.no_grad():\n","    for image_path in tqdm(image_paths):\n","        load_path = os.path.join(source_folder, image_path)\n","        image = Image.open(load_path)\n","\n","        # convert PIL Image to PyTorch tensor\n","        image = image_transform(image).to(device)\n","        image = torch.unsqueeze(image, dim=0)\n","\n","        # estimate the depth map from each image\n","        image_depth = depth_estimator(image)  # size (1, 3, 256, 256)\n","        image_depth = 1000 * image_depth / (torch.max(image_depth) - torch.min(image_depth))\n","\n","        # save depth maps\n","        image_depth = image_depth[0].cpu().numpy().astype(np.uint16)\n","        image_depth = Image.fromarray(image_depth)\n","\n","        id = image_path.split(\"_\")[1].split(\".\")[0]\n","        padded_id = id.zfill(4)\n","        save_name = str(padded_id)+'.png'\n","        save_path = os.path.join(destination_folder, save_name)\n","        image_depth.save(save_path)\n","\n","        # # show depth maps\n","        # plt.imshow(image[0].permute(1, 2, 0).cpu())\n","        # plt.show()\n","        # plt.imshow(image_depth)\n","        # plt.show()\n","        # break\n"],"metadata":{"id":"5IUhLxV2oLtQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1ad36846-6399-442b-e9cd-fbf74f4cef22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1619 [00:00<?, ?it/s]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n","\n"," 52%|█████▏    | 836/1619 [06:08<05:53,  2.22it/s]"]}]}]}